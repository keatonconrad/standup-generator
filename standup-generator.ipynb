{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The goal of this notebook is to demonstrate the usage of [OpenAI's GPT-2](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) to generate standup comedy jokes. Specifically, I was interested in its ability to generate longer-form, coherent jokes, as opposed to one-liners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "This project uses my fork of [minimaxir's gpt-2-simple](https://github.com/minimaxir/gpt-2-simple), which allows us to use Python lists as inputs into the model. We also install the necessary dependencies for web scraping, data cleaning, and data saving and loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "path = os.path.abspath('src/gpt_2_simple')\n",
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (4.60.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.7/site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.7/site-packages (2021.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "fatal: destination path './src/gpt_2_simple' already exists and is not an empty directory.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm\n",
    "%pip install bs4\n",
    "%pip install regex\n",
    "!git clone 'https://github.com/keatonconrad/gpt-2-simple' './src/gpt_2_simple'\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from src.gpt_2_simple import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Preparation\n",
    "\n",
    "This project uses the 345M parameter model of GPT-2. While other sizes are available, this size was chosen as a balance between speed and quality of results. We download the model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 866Mit/s]                                                      \n",
      "Fetching encoder.json: 1.05Mit [00:00, 4.97Mit/s]                                                   \n",
      "Fetching hparams.json: 1.05Mit [00:00, 1.61Git/s]                                                   \n",
      "Fetching model.ckpt.data-00000-of-00001: 1.42Git [01:14, 19.0Mit/s]                                 \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 1.19Git/s]                                               \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:00, 5.47Mit/s]                                                \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 8.27Mit/s]                                                      \n"
     ]
    }
   ],
   "source": [
    "model_size = '345M'\n",
    "if not os.path.isdir(os.path.join('models', model_size)):\n",
    "    gpt2.download_gpt2(model_name=model_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "To collect the data for training, we scrape standup comedy transcripts from [scrapsfromtheloft.com](scrapsfromtheloft.com). We load a list of links from a .txt file. These links are sourced based on my own personal comedy tastes, favoring comedians with longer-form jokes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_transcript(url):\n",
    "    # Scrapes transcript data from scrapsfromtheloft.com\n",
    "    page = requests.get(url).text # Get all data from URL\n",
    "    soup = BeautifulSoup(page, 'html.parser') # Read as an HTML document\n",
    "    text = [p.text for p in soup.find(class_='elementor-widget-theme-post-content').find_all('p')] # Pull out all text from post-content\n",
    "    return text\n",
    "\n",
    "with open('./urls.txt') as f:\n",
    "    urls = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:47<00:00,  2.69s/it]\n"
     ]
    }
   ],
   "source": [
    "transcripts = [url_to_transcript(u) for u in tqdm(urls)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Storage and Loading\n",
    "\n",
    "The transcripts are saved using the pickle module. These transcripts can then be loaded later from the pickled files for speed and to avoid unnecessary web scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save transcripts\n",
    "# !mkdir transcripts\n",
    "\n",
    "for i in range(len(urls)):\n",
    "    with open(\"transcripts/\" + str(i) + \".txt\", \"wb\") as file:\n",
    "        pickle.dump(transcripts[i], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled files\n",
    "transcripts = []\n",
    "for i in range(len(urls)):\n",
    "    with open(\"transcripts/\" + str(i) + \".txt\", \"rb\") as file:\n",
    "        transcripts.append(pickle.load(file))\n",
    "transcripts = [item for sublist in transcripts for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "Since the data is raw text scraped from the web, it should be cleaned for best results before fine-tuning the model.\n",
    "\n",
    "First, we remove the text between brackets, and the brackets themselves. This is commonly seen in this dataset as \"[audience laughing]\" or similar. These instances of bracketed text do not usually add to the jokes themselves, so we don't want to train the model with them present.\n",
    "\n",
    "Then, we remove words with numbers in them, new lines, and all non-printable characters to ensure we are working with only alpha characters. \n",
    "\n",
    "Only jokes that are 50 characters or longer at this point are used. This is to ensure we are working with jokes of substantial length, to remove unwanted lines we didn't catch before (stage directions, etc.), and again because I am primarily interested in the model's ability to work with long-form comedic material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning\n",
    "printable = set(string.printable)\n",
    "\n",
    "jokes = []\n",
    "for paragraph in transcripts:\n",
    "    cleaned = re.sub(r'\\[[^)]*\\]', '', paragraph)  # Removes text within []\n",
    "    cleaned = re.sub('\\w*\\d\\w*', '', cleaned)  # Removes words with numbers in them\n",
    "    cleaned = re.sub('\\n', ' ', cleaned)  # Removes new lines\n",
    "    cleaned = ''.join(filter(lambda x: x in printable, cleaned))  # Removes all non-printable characters\n",
    "    if len(cleaned) > 50:  # Removes short paragraphs in favor of longer jokes\n",
    "        # cleaned = '<|startoftext|> ' + cleaned + ' <|endoftext|>'\n",
    "        jokes.append(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation and Preparation\n",
    "\n",
    "First, we shuffle the list of jokes to mitigate any potential bias from the order.\n",
    "\n",
    "Then, we split the jokes into two datasets: one for training and one for validation. This is to ensure we are evaluating the results on an unseen or \"hold-out\" set of jokes. I used a split of 0.2 here, meaning 80% of the data will be used for training, and the remaining 20% will be used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1701\n",
      "Validation samples: 425\n"
     ]
    }
   ],
   "source": [
    "val_split = 0.2\n",
    "\n",
    "num_train_samples = int(len(jokes) * (1 - val_split))\n",
    "num_val_samples = int(len(jokes) * val_split)\n",
    "print('Training samples:', num_train_samples)\n",
    "print('Validation samples:', num_val_samples)\n",
    "\n",
    "dataset = jokes[:num_train_samples]\n",
    "val_dataset = jokes[num_val_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fine-Tuning\n",
    "\n",
    "Now we are ready to fine-tune the model. This Python package makes it easy.\n",
    "\n",
    "We begin by starting a Tensorflow session. We input our data and iterate over it 501 times (the extra 1 is to ensure we get a final validation reading)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = gpt2.start_tf_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/src/gpt_2_simple/gpt_2_simple/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /root/src/gpt_2_simple/gpt_2_simple/src/memory_saving_gradients.py:67: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n",
      "Instructions for updating:\n",
      "Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n",
      "Loading checkpoint models/345M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/345M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/345M/model.ckpt\n",
      "100%|██████████| 1/1 [00:00<00:00, 216.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 240.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 335938 tokens\n",
      "Training...\n",
      "[10 | 22.62] loss=3.69 avg=3.69\n",
      "[20 | 36.60] loss=3.59 avg=3.64\n",
      "[30 | 50.60] loss=3.41 avg=3.56\n",
      "[40 | 64.60] loss=3.14 avg=3.46\n",
      "[50 | 78.60] loss=3.20 avg=3.40\n",
      "[60 | 92.61] loss=2.59 avg=3.27\n",
      "[70 | 106.70] loss=3.20 avg=3.26\n",
      "[80 | 120.80] loss=3.35 avg=3.27\n",
      "[90 | 134.93] loss=3.11 avg=3.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100 | 149.08] loss=3.36 avg=3.26\n",
      "Calculating validation loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101 | 179.16] validation loss = 3.30\n",
      "[110 | 193.42] loss=2.70 avg=3.21\n",
      "[120 | 207.75] loss=3.18 avg=3.21\n",
      "[130 | 222.15] loss=3.40 avg=3.22\n",
      "[140 | 236.62] loss=3.23 avg=3.22\n",
      "[150 | 251.20] loss=3.67 avg=3.25\n",
      "[160 | 265.85] loss=3.22 avg=3.25\n",
      "[170 | 280.22] loss=3.62 avg=3.28\n",
      "[180 | 294.45] loss=2.56 avg=3.23\n",
      "[190 | 308.58] loss=3.00 avg=3.22\n",
      "[200 | 322.68] loss=2.78 avg=3.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== SAMPLE 1 ========\n",
      " about? I know that much. Yeah, shes a hero, baby. And Im okay, but you still want me to be with me? Okay. Youre a bitch. <|endoftext|>\n",
      "<|startoftext|> All this really does is piss everybody off, gives me a bunch of time to come in here and tell you a joke. Yeah, but if you ever tell me a joke, I will be fucking mad at you. Youre like, yeah, thats what you said. Okay. Yeah, but I did it. I did it. Its fine. I did it. I gave it a shot. I did, we did it. It was, wasnt it? I gave it a shot. I dont want you, you got nothing against the show youre doing. Its just, you and I dont want you to tell it that in your show, if you tell me a joke, I will be like, Yeah, you gotta do it and Im not standing around, You know? Yeah, if you told me a joke, you have nothing against the show you say. Im your friend. And youre like, yeah, you read that joke and you still give it a shot, you still give the joke? Youre like, I read it. <|endoftext|>\n",
      "<|startoftext|> I didnt want to tell you a story right now. Im telling a story. I want you to hear one song. Its about a year from now where I have taken my hat off. Ive turned into a monster. <|endoftext|>\n",
      "<|startoftext|> I dont believe it when you say its okay to cry inside, you have not even been to the store since. So you feel the need for somebody to come over and help you. Its your mom, that little girl, you cry in the middle of the night. Yeah. So she buys you a ticket to take it back. Its not your fault. Cause youre on the ticket and I get up to your mom. You do your dishes. You pick up your mom, throw it away this little guy. He gets up to my mom. You throw it away. And your mom in the middle of the night. Thats how fast youre going. Thats going. You look around like a god damn giant. He gets to the bus, pulls it out, wipes it over my chest. I dont. You know where youre going. Youll be like, hey, we just made a guy go fuck yourself and shut him door. You didnt come in here. You just took your mom. I didnt come here. You just came in here. He took your mom. You just turned your back around. You just had to take your mom. You dont see your mom. You dont see your mom. You just gave her a bag of chips. Just took your mom. You got a bag of chips stuck in front of your kids. Theyd be like, thats too dangerous for you to get away from your mom. You dont know. You dont know why youre saying that. I dont know. Im like, I dont know. I cant even believe you. I dont. I cant know. Im like, well get away from your mom. Oh. God. Youre doing an impression of you with this joke. Its kind of a little hard, you know? You know, but I did a joke right, so, I went to a joke of some joke. The joke is that Im taking the hit and not having an impact on your own show. <|endoftext|>\n",
      "<|startoftext|> Because are you gonna try to make everyone laugh, all right? <|endoftext|>\n",
      "<|startoftext|> Um, I have to go and talk about my wife and kids. We dont know who we dont have to go and celebrate anymore. But thats because people dont know you anymore. Youll be watching. Youll be like, hey, were gonna watch, you want, me? Uh, yeah. My kid dont tell you how much we dont hear from you. Yeah, why dont we tell you now that? Yeah, you dont want to watch. Yeah, why dont you buy me a watch so you can walk in. Yeah, just walk outside, its okay, dude. You want to watch. I didnt think I would be happy, but we were having a conversation, you know, now, you dont want me to buy that thing. I dont want you to buy any thing you dont wanna buy. I want you to buy it. I dont want you to buy it. I dont want you to ever buy it. Thats why I didnt buy it. Cause I dont. You got a watch, you give me a watch. You want a watch, you give me a watch. You want a watch on your back, you give me a watch\n",
      "\n",
      "Calculating validation loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:27<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[201 | 372.06] validation loss = 3.23\n",
      "[210 | 386.26] loss=3.19 avg=3.19\n",
      "[220 | 400.47] loss=2.13 avg=3.14\n",
      "[230 | 414.71] loss=1.69 avg=3.07\n",
      "[240 | 428.97] loss=2.52 avg=3.04\n",
      "[250 | 443.27] loss=1.66 avg=2.98\n",
      "[260 | 457.58] loss=1.83 avg=2.93\n",
      "[270 | 471.93] loss=2.63 avg=2.92\n",
      "[280 | 486.33] loss=3.42 avg=2.94\n",
      "[290 | 500.75] loss=2.90 avg=2.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300 | 515.25] loss=2.13 avg=2.91\n",
      "Calculating validation loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:28<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[301 | 543.89] validation loss = 3.10\n",
      "[310 | 558.70] loss=1.36 avg=2.85\n",
      "[320 | 573.34] loss=3.47 avg=2.87\n",
      "[330 | 587.73] loss=2.23 avg=2.85\n",
      "[340 | 602.03] loss=2.15 avg=2.83\n",
      "[350 | 616.27] loss=3.37 avg=2.84\n",
      "[360 | 630.49] loss=1.48 avg=2.80\n",
      "[370 | 644.69] loss=1.98 avg=2.77\n",
      "[380 | 658.90] loss=0.90 avg=2.71\n",
      "[390 | 673.10] loss=3.54 avg=2.74\n",
      "[400 | 687.31] loss=1.75 avg=2.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== SAMPLE 1 ========\n",
      " And I would say, what do you want me to do? Im like, you know, I want this guy to do one-on-one with me to really please you, but he did all these things for you, you know,  to his house. So <|endoftext|>\n",
      "<|startoftext|> Thank you for coming out so really, you know, your favorite thing that I ever did is I went to the gym the other day. I thought it was a little thing that I would do in order to have to get rid of a little guy named Matt Stamci. Like, I was hoping for him to get rid of this little guy named Rory, which is a little old, you know, a little old man. I just thought that was a little bit my chance to tell me that Rory was, you know, his little boy. I was hoping for Rory to get rid of this little boy and get some respect from the people of England, where they are so fond of the English. I was hoping that they would just do that, you know, to keep him in the fucking basement so that my little boy could talk to my friend Rory. So I was hoping that Rory would just, like, go out there and do some sports shit that I thought I could do to earn a living room, you know, a living room. Like, I was hoping that wasnt enough, you know? I didnt, you know, get a toy. I was hoping that wasnt enough for what, you know, my hopes for a living room. And I was hoping that was good enough for me for me for me, for me, for me, for me, for me. It was just fucking crazy, man. It was really emotional. It was crazy, man, I was expecting a lot of people to be around to get some respect for me, but it just, you know, was really, you know, the ball. The ball was on a kid. It was a little, and I know what the kid was doing, so The ball was going to my brain, and I was just standing there like an out of nowhere, you know, my friend, my friend of sorts. And I was doing this on purpose, so that you can talk to me about what you were doing, but I just wanted to have it so I could talk. You know, you know, my goal, you know? I just dont fucking do shit. I dont really do shit, you know, cause Im not trying to be a procrastinator anymore, you know? But I wanted to do something, cause I didnt have a toy, Im sorry. My goal was, as I always say, the last thing to do with my house was, you know, the basement of my house to myself, so I could talk all night and then make a call for Rory in the car. The ball was on the table. The ball was on the plate, I could only answer one time. I mean, it was like there was not a male person, like, You have to lie down and go, but dont do anything. I was just gonna lie like an out of nowhere, and that was, you know, Rorys balls, and I could barely breathe, you know. I was just standing there like an out of frustration tired of being the boss all this other people were doing, you know? I could feel the pressure on the side from this other party. I could feel the ball on my back. I looked over, saw it was him looking at me. Thats what Im supposed to do, you know? Cause he was sitting there and I was like, Look how fucking high he was, you little piece of shit, man. You know, like, my boyfriend, so Im lying there looking over the table, I was gonna have a party, and Im gonna have a party, and then all of the people came over and they all started clapping, and I was like, You got the ball, I got the ball. The ball is on the table, and the table top, you know, and the ball is going to my head, and now I thought that I had to lie just so that people wouldnt get in trouble, you know? And I was like, Guys, this is a little much! And then some guys came over, I guess. Guys, I want you to have the ball, you know. Im doing no such thing. Im lying on the ground looking like an out of an out of a hit man. Now Im trying, you know, to make a call. I went to the mall the other day, and they had a display of Wonder Bread on their television. I had a booth. They were like, Whoa, Wonder Bread! Wonder Bread! We want Wonder Bread. We want Wonder Bread. Wonder Bread! I was like, Yeah. I can do Wonder Bread. I can do Wonder Bread. Then Wonder Bread. That\n",
      "\n",
      "Calculating validation loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:27<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[401 | 734.23] validation loss = 2.96\n",
      "[410 | 748.54] loss=2.88 avg=2.71\n",
      "[420 | 762.85] loss=0.83 avg=2.66\n",
      "[430 | 777.21] loss=1.75 avg=2.63\n",
      "[440 | 791.61] loss=3.24 avg=2.65\n",
      "[450 | 806.04] loss=2.68 avg=2.65\n",
      "[460 | 820.55] loss=0.97 avg=2.61\n",
      "[470 | 835.17] loss=2.32 avg=2.60\n",
      "[480 | 849.88] loss=2.44 avg=2.59\n",
      "[490 | 864.68] loss=2.80 avg=2.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500 | 879.17] loss=2.78 avg=2.60\n",
      "Calculating validation loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:27<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[501 | 907.14] validation loss = 2.85\n",
      "Saving checkpoint/run1_standup/model-501\n"
     ]
    }
   ],
   "source": [
    "gpt2.finetune(\n",
    "\tsess,\n",
    "\tdataset=dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    val_every=100,\n",
    "\tmodel_name=model_size,\n",
    "\tsteps=501,  # number of iterations\n",
    "\trestore_from='fresh',  # start from scratch\n",
    "\trun_name='run1_standup',  # directory where trained model will be located\n",
    "\toverwrite=True,\n",
    "\tprint_every=10,\n",
    "\tsample_every=200,  # output results every 200 steps\n",
    "\tlearning_rate=0.001,\n",
    "\tsave_every=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results\n",
    "\n",
    "We can now use the fine-tuned model to generate standup comedy jokes! After some testing, I found that a temperature of 0.8 produced results that were more sensical and sometimes had an element of humor to them, as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|> All right. I know, I cant wait to get back to the old days of just not doing good inside a building. Then get a good one. And this is cool for people everywhere. Its not a new problem. You dont even have to be a saint. Youre a saint. But God gives you a prayer and you can do everything you want the rest of your lives. You go find one. Its a miracle. Thatsnt the God, Im like a saint. And the other saints turned and said, I wasnt introduced to Him, its a gift. So I was in a hotel room with the rest of the other saints and we went and we walked through Church. Everybody was there. We went and we sat and were like, Uh, I know, Jesus! And then Jesus Christ! That Jesus! Really? Im like, Jesus! What the fuck are you trying to say a Godfather didnt want? Somebody is like, Um, Jesus! And I was like, Jesus? And Jesus! Jesus Christ! Jesus! Jesus!  Hrs. Yeah! Jesus! Jesus! You know, Jesus! I know, you never hear a Jesus Christ! Jesus! Jesus! Jesus! Jesus! Jesus! Jesus! Jesus! Jesus! –Jesus! Came! I was like, What the fuck? I didnt know what Jesus meant. You dont know what Jesus meant? What the fuck is that? Jesus! What if is that delicious? What if can we get Christ?\" What if just like, Its like a two hands game. Yeah! Did it? You go, I dont know. Do we play Monopoly? Oh, Monopoly. Its like Monopoly, man! I dont care. \n",
      "====================\n",
      "<|startoftext|> And if youve ever been in a restaurant and you want to see a waiter with his hands, he has a helicopter and a dolphin face. \n",
      "====================\n",
      "<|startoftext|>      God knows! Lets do some science fiction, shall do some science fiction, right?                  I believe my faith! I Believe! I believe! Im here! And if you dont believe in it, youre wrong. Because you cant believe in it, you can never see it. You are not seeing it! I mean rite my life. Ive been like, This is my life. Ive been like, Uh, I just woke up, and I thought I could hear and he goes, I dont know. And I was like, No! Im here! Im here! I was like, Thats your life. I just I dont feel it! Im here! Huh? It was like I thought I could do it. But its like, Youre married with a hot girl, and youre like, You just wanna fuck her, and shes like, Thats your baby! Which is in itself a crime. And then then youre like, Yeah! And its like, Yeah! Ive already started raping this motherfucker! \n",
      "====================\n",
      "<|startoftext|>   But they didnt have the television, so they didnt get some cable, and they just showed me what they had. Theyre like, Hey, guy, lets go down. Okay. \n",
      "====================\n",
      "<|startoftext|> That was a great year for me. The water is no good, some people, dont they? Thats a problem. I dont know that. Yeah, its a problem. So, hes like, Look, then Ill give a man a drink, okay? and the water freezes, hes like, Im in this dude, okay. So, I grab the glass and went, Thank you, wits a brand-all right thing. And theres no proof of that. Like, its just like, You have no choice but to keep it cold. And it makes the water hotter, and the glass is like, You made it. And you take it, Cause coconut oil, like, finishes the water. Every time I urinate, I go, Im in this now, okay. Look? And if youre offended by this, please just go,  to the table, okay? You got any of those sorts of thoughts, you know. You dont do it. You just go, I dont mind. I dont want to deal with it. And if youre offended, please just go, No one has that. Im like, Me, Im gonna have to figure this one out. What if it was me? What if its me? If its me, I need a a bathroom, and Im like, How? Im like, Yeah! Youre all having breakfast, and youre like, You should change your mind, and I dont even know what that means? Or, its like, Whats the name of the baby up there? Three things. Your mom can change your mind, but Im so mean. Im thinking, I dont know. Shes saying, I cant change it, and so I just go, You already know it, and then she dies. I know it sounds like someone bought a mirror at the pool, like,   of them. Most are crying. I get like, thats like God breathing, ok? Like like I was about to change my mind, and I was like, What was God? What? What did he say? What does he mean? What did he say? What did he did that was? What did he say? What was it? What was he say? What was it? What was he say? What was his name? What was it? What did he say? What did he say? What was his last name? What did he do? What was his last name? What \"did he do? Two years before I got married? What a strangety. What kind of a surprise is that was that Jesus Christ! Jesus Christ! Jesus Christ! Jesus Christ! Jesus Christ! Jesus Christ! Jesus Christ! He is being crucified.  And the way you argue with kids, youre arguing with this grown male nerd. Like, this is like a bone-briner. And Im like, Why? He is being crucified. \n",
      "====================\n",
      "<|startoftext|> Tell him youre getting some health food, have a good time, and create a new hashtag. \n",
      "====================\n",
      "<|startoftext|> There are those three steps. And the way they all went through them. I wasnt gonna do this. I was gonna go see a doctor explaining it to the doctor. Are you gonna accept that? And the doctor goes, You are gonna look for my wife. And I was like, What the fuck are you doing? I didnt have to. Not yet.\" And she goes, Ill look for my wife. And I went, You know? And she goes, You have to tell me. \n",
      "====================\n",
      "<|startoftext|> So now I was like, There isnt a way to not have that in there! and it was like, Why? Id be like, Yeah! And it was like, I am in this! Which is kinda all true, but its not so great. And then, you forget it, and youre like, Oh, yeah. I mean, I cant be like, Have you been in this situation where someone falls asleep at a party. And theyre like, Is this what happened? And youre like, Is this what happened? And height murable. What happened? Im like, No! No. Well, Mr. Gaffigan. I mean, Im losing my vision. And he went, \n",
      "====================\n",
      "<|startoftext|> I tell you why, cause I learned about myself. I have a tiny penis, and I was like, OK. And it was like, No! Im gay! Which is weird, because I dont know where I came from, and Im Mexican, so that seemed like a foreign language to me. And so it was like, I dont have it! So I was like, and it was like, Um, so Im Mexican, and if you were upset, you know that it sounds like you dont have to know, you can put your business cards and pay that bill. So if youre like, I guess Im Mexican. Make me, you know, stop crying. Im Mexican. Im Mexican. My mom, if youve ever been around Mexicans, you know, has a phobia. And so I was like, I dont have it. You know what happens? When I was a kid, the first time, I had a phobia, so she goes, You should just look up. \n",
      "====================\n",
      "<|startoftext|> And then, Im  years old. Im like, Hey, Im gonna direct flight out of the airport, but itll be, like,  minutes. And I got my first-ever been on the plane. It was very cold, had somac and a -hour layover, and were making ice cream, and so we were like, Well, can you bring your big chair on. And then, we got the keys to the country. And we got married at a very young age, and we had, like, a -hour layover. And this is right. \n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(\n",
    "\tsess,\n",
    "    run_name='run1_standup',\n",
    "\tnsamples=10,\n",
    "\ttemperature=0.8,\n",
    "\tprefix='<|startoftext|>',\n",
    "\ttruncate='<|endoftext|>'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 1.15 Python 3.7 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/tensorflow-1.15-gpu-py37-cu110-ubuntu18.04-v8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
